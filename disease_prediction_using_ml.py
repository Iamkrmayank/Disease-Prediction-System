# -*- coding: utf-8 -*-
"""Disease Prediction Using ML.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1nafxd7ezWpbjyQA85AR6gMffjOAX2xbZ
IMPORT DEPENDANCIES
"""

#for dealing with multidimensional arrays
import numpy as np
#for data analysis on the dataset
import pandas as pd
#for data mining and data processing
import sklearn
#for visualizations & graphs
import matplotlib.pyplot as plt
import seaborn as sns
#to standardize data in a particular range
from sklearn.preprocessing import StandardScaler
#to spit data into train & test respectively
from sklearn.model_selection import train_test_split
#importing the required ML algorithms
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.ensemble import ExtraTreesClassifier

"""DATA COLLECTION & ANALYSIS
(PIMA DIABETES DATASET)

"""

#load diabetes dataset to pandas dataframe
diabetes_dataset=pd.read_csv('/content/diabetes.csv')
diabetes=diabetes_dataset.dropna()

#print first 5 rows
diabetes_dataset.head()

#check whether cols are true/false based on dtypes
diabetes_dataset.info()

#data correlation
diabetes_dataset.corr()

#number of rows and columns in the dataset
diabetes_dataset.shape

#getting statistical measures of data
diabetes_dataset.describe()



#counts for diabetic and non diabetic
diabetes_dataset['Outcome'].value_counts()

"""0- non diabetic
1- diabetic
"""

diabetes_dataset.groupby('Outcome').mean()

"""-Group datasets,draw meaningful insights
-eg: glucose,age factors

"""

#seperate data and labels
X= diabetes_dataset.drop(columns='Outcome',axis=1)
Y= diabetes_dataset['Outcome']

print(X)

print(Y)

"""DATA STANDARDIZATION

-Standardize data in a machine learning model to make better predictions 
via std scaler function

"""

scaler= StandardScaler()

scaler.fit(X)

standardized_data=scaler.transform(X)

#in order to bring values within the similar range
print(standardized_data)
  
X= standardized_data
Y= diabetes_dataset['Outcome']

"""X- represents the data, Y-represents the model"""

print(X)
print(Y)

"""TRAIN TEST SPLIT

X train-- train X_train data without X_test

X-test-- train X_train data using X_test(ML model makes prediction in this unknown data)

Y-train -- represents labels for the X_train data

Y_test -- represents labels for X_test data(i.e diabetic/ non--diabetic)

Stratify- split the data in same proportion, avoid interchange of data

random_state-- replicate data in a certain manner
"""

X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""TRAINING THE MODEL

SVC- support vector classifier
"""

classifier = svm.SVC(kernel='linear')

#training the support vector machine classifier
classifier.fit(X_train, Y_train)

"""LR-Logistic Regression"""

log_reg = LogisticRegression(random_state=1, max_iter=1000)

log_reg.fit(X_train,Y_train)

y_pred=log_reg.predict(X_test)
y_pred

"""RF- Random Forest"""

#randomforest
forest=RandomForestClassifier(n_estimators=100,criterion="entropy",random_state=2)
forest.fit(X_train,Y_train)

#predict for forest classifier.
y_pred=forest.predict(X_test)
y_pred

"""KNN- K-Nearest Neighbors"""

KNN=KNeighborsClassifier(n_neighbors=1)
KNN.fit(X_train,Y_train)

#predict for KNN.
y_pred=KNN.predict(X_test)

print(confusion_matrix(Y_test,y_pred))
print(classification_report(Y_test,y_pred))

"""MODEL EVALUATION

Accuracy Score
"""

#accuracy score on the training data
X_train_prediction=classifier.predict(X_train)
#accuracy score on test data
X_test_prediction=classifier.predict(X_test)

training_data_accuracy=accuracy_score(X_train_prediction,Y_train)
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)

print('Accuracy score of the training data:',training_data_accuracy)
print('Accuracy score of the test data:',test_data_accuracy)

#accuracy score for logisitic regression
print("Logistic Regression Classifier  Accuracy: ",accuracy_score(Y_test,y_pred))

#accuracy score for Random Forest
print("Random Forest Classifier Training Accuracy: ",forest.score(X_test,Y_test))

#accuracy score for KNN 
print("KNN classifier training accuracy: ",KNN.score(X_test,Y_test))

"""accuracy= 0.78.. -- Means out of 100 times model is predicting 78 times correct predictions

Accuracy=0.77.. --Means the ML model performs well on test data too

No Overfitting(i.e higher value of train data than compared to test data)

MAKING A PREDICTIVE SYSTEM
"""

input_data=(1,89,66,23,94,28.1,0.167,21)

#Change the input data to a numpy array
data_input_as_numpy_array=np.asarray(input_data)

#Reshape array as we predict for one instance
data_input_reshaped=data_input_as_numpy_array.reshape(1,-1)

#Standardize input data
std_data=scaler.transform(data_input_reshaped)
print(std_data)

prediction= classifier.predict(std_data)
print(prediction)

if (prediction[0]==0):
   print('Person is non diabetic')
else:
  print('Person is diabetic')

"""reshape(1,-1)-- Not reshaping the array for 768 datasets, 
but only for any one instance in particular

DATA VISUALIZATION
"""

#order of importance
v=diabetes_dataset[['Glucose', 'BMI', 'Age', 'Pregnancies', 'SkinThickness',
       'Insulin', 'DiabetesPedigreeFunction']]
w=diabetes_dataset.iloc[:,8]

model = ExtraTreesClassifier()
model.fit(v,w)
print(model.feature_importances_) 
#plotting graph in order of their features of importance for better visualization
feat_imp = pd.Series(model.feature_importances_, index=v.columns)
feat_imp.nlargest(20).plot(kind='bar')
plt.show()

#the unstable relationship between insulin & BP
sns.relplot(x="BloodPressure", y="Insulin", data = diabetes)

diabetes_clean = diabetes[diabetes['Insulin'] != 0]
diabetes_clean2 = diabetes_clean[diabetes_clean['Glucose'] != 0]
ax = sns.regplot(x="Glucose", y="Insulin", data=diabetes_clean2)

